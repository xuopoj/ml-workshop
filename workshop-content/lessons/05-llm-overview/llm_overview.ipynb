{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ç¬¬å››è¯¾ï¼šä¸»æµå¤§è¯­è¨€æ¨¡å‹\n",
    "\n",
    "**è¯¾ç¨‹æ—¶é•¿**: 0.5å°æ—¶  \n",
    "**è¯¾ç¨‹ç›®æ ‡**: \n",
    "- äº†è§£å½“å‰ä¸»æµçš„å¤§è¯­è¨€æ¨¡å‹\n",
    "- ç†è§£ä¸åŒæ¨¡å‹çš„ç‰¹ç‚¹å’Œåº”ç”¨åœºæ™¯\n",
    "- ä¸ºåç»­LLMè®­ç»ƒå’Œæ¨ç†è¯¾ç¨‹æ‰“ä¸‹åŸºç¡€\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç›®å½•\n",
    "\n",
    "1. å¤§è¯­è¨€æ¨¡å‹æ¦‚è¿°\n",
    "2. æ–‡æœ¬å¤§æ¨¡å‹\n",
    "   - 2.1 GPTç³»åˆ—\n",
    "   - 2.2 LLaMAç³»åˆ—\n",
    "   - 2.3 Qwenç³»åˆ—\n",
    "   - 2.4 å…¶ä»–ä¸»æµæ¨¡å‹\n",
    "3. æ€è€ƒæ¨¡å‹ï¼ˆReasoning Modelsï¼‰\n",
    "   - 3.1 DeepSeekç³»åˆ—\n",
    "   - 3.2 Qwenæ€è€ƒæ¨¡å‹\n",
    "4. ä»£ç æ¨¡å‹\n",
    "   - 4.1 Qwen-Coderç³»åˆ—\n",
    "   - 4.2 å…¶ä»–ä»£ç æ¨¡å‹\n",
    "5. å¤šæ¨¡æ€æ¨¡å‹\n",
    "   - 5.1 Qwen-VLç³»åˆ—\n",
    "   - 5.2 GLM-4V\n",
    "   - 5.3 å…¶ä»–å¤šæ¨¡æ€æ¨¡å‹\n",
    "6. æ¨¡å‹é€‰æ‹©æŒ‡å—\n",
    "7. æ€»ç»“ä¸å±•æœ›"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# å¯¼å…¥å¯è§†åŒ–åº“\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom matplotlib import rcParams\nimport pandas as pd\n\n# è®¾ç½®ä¸­æ–‡æ˜¾ç¤º\nrcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']\nrcParams['axes.unicode_minus'] = False\n\nprint(\"Environment setup complete!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. å¤§è¯­è¨€æ¨¡å‹æ¦‚è¿°\n",
    "\n",
    "### 1.1 ä»€ä¹ˆæ˜¯å¤§è¯­è¨€æ¨¡å‹ï¼Ÿ\n",
    "\n",
    "**å¤§è¯­è¨€æ¨¡å‹ (Large Language Model, LLM)** æ˜¯åŸºäºTransformeræ¶æ„ï¼Œåœ¨æµ·é‡æ–‡æœ¬æ•°æ®ä¸Šé¢„è®­ç»ƒçš„æ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚\n",
    "\n",
    "#### æ ¸å¿ƒç‰¹å¾\n",
    "\n",
    "1. **è§„æ¨¡å¤§**\n",
    "   - å‚æ•°é‡ï¼šä»10äº¿åˆ°æ•°ä¸‡äº¿\n",
    "   - è®­ç»ƒæ•°æ®ï¼šæ•°ä¸‡äº¿token\n",
    "   - è®­ç»ƒç®—åŠ›ï¼šæ•°åƒåˆ°æ•°ä¸‡GPU/TPU-æœˆ\n",
    "\n",
    "2. **æ¶Œç°èƒ½åŠ› (Emergent Abilities)**\n",
    "   - é›¶æ ·æœ¬å­¦ä¹  (Zero-shot)\n",
    "   - å°‘æ ·æœ¬å­¦ä¹  (Few-shot)\n",
    "   - æ€ç»´é“¾æ¨ç† (Chain-of-Thought)\n",
    "   - æŒ‡ä»¤éµå¾ª (Instruction Following)\n",
    "\n",
    "3. **é€šç”¨æ€§**\n",
    "   - ä¸éœ€è¦é’ˆå¯¹ç‰¹å®šä»»åŠ¡å¾®è°ƒ\n",
    "   - é€šè¿‡promptå·¥ç¨‹é€‚åº”ä¸åŒåœºæ™¯\n",
    "\n",
    "### 1.2 LLMçš„å‘å±•å†ç¨‹\n",
    "\n",
    "```\n",
    "2018\n",
    "  GPT-1 (117M)\n",
    "  BERT (340M)\n",
    "    â†“\n",
    "2019  \n",
    "  GPT-2 (1.5B)\n",
    "  RoBERTa, T5\n",
    "    â†“\n",
    "2020\n",
    "  GPT-3 (175B) â† æ¶Œç°èƒ½åŠ›å¼€å§‹æ˜¾ç°\n",
    "    â†“\n",
    "2021\n",
    "  PanGu (200B), GLM (130B)\n",
    "    â†“\n",
    "2022\n",
    "  ChatGPT â† çˆ†å‘ç‚¹\n",
    "  LLaMA (7B-65B)\n",
    "    â†“\n",
    "2023\n",
    "  GPT-4 (å¤šæ¨¡æ€)\n",
    "  LLaMA 2, Qwen, Baichuan\n",
    "  Claude 2, Gemini\n",
    "    â†“\n",
    "2024\n",
    "  Qwen2.5, LLaMA 3, DeepSeek-V2\n",
    "  Claude 3, Gemini 1.5\n",
    "    â†“\n",
    "2025\n",
    "  DeepSeek-R1, Qwen3\n",
    "  ...\n",
    "```\n",
    "\n",
    "### 1.3 LLMçš„è®­ç»ƒæµç¨‹\n",
    "\n",
    "```\n",
    "é˜¶æ®µ1: é¢„è®­ç»ƒ (Pre-training)\n",
    "  - æ•°æ®: ç½‘é¡µã€ä¹¦ç±ã€ä»£ç ç­‰æµ·é‡æ–‡æœ¬\n",
    "  - ä»»åŠ¡: è¯­è¨€å»ºæ¨¡ï¼ˆé¢„æµ‹ä¸‹ä¸€ä¸ªè¯ï¼‰\n",
    "  - äº§ç‰©: Baseæ¨¡å‹\n",
    "     â†“\n",
    "é˜¶æ®µ2: ç›‘ç£å¾®è°ƒ (Supervised Fine-Tuning, SFT)\n",
    "  - æ•°æ®: é«˜è´¨é‡çš„æŒ‡ä»¤-å›ç­”å¯¹\n",
    "  - ä»»åŠ¡: å­¦ä¹ å¦‚ä½•éµå¾ªæŒ‡ä»¤\n",
    "  - äº§ç‰©: Instruct/Chatæ¨¡å‹\n",
    "     â†“\n",
    "é˜¶æ®µ3: äººç±»åé¦ˆå¼ºåŒ–å­¦ä¹  (RLHF)\n",
    "  - æ•°æ®: äººç±»åå¥½æ•°æ®\n",
    "  - ä»»åŠ¡: å¯¹é½äººç±»ä»·å€¼è§‚\n",
    "  - äº§ç‰©: Alignedæ¨¡å‹\n",
    "```\n",
    "\n",
    "### 1.4 å…³é”®æŠ€æœ¯\n",
    "\n",
    "| æŠ€æœ¯ | ä½œç”¨ | ä»£è¡¨æ¨¡å‹ |\n",
    "|------|------|----------|\n",
    "| **Decoder-only Transformer** | åŸºç¡€æ¶æ„ | å‡ ä¹æ‰€æœ‰ç°ä»£LLM |\n",
    "| **Instruction Tuning** | æŒ‡ä»¤éµå¾ª | InstructGPT, Qwen-Chat |\n",
    "| **RLHF/PPO** | äººç±»å¯¹é½ | ChatGPT, Claude |\n",
    "| **Chain-of-Thought (CoT)** | æ¨ç†èƒ½åŠ› | GPT-4, DeepSeek-R1 |\n",
    "| **MoE** | é«˜æ•ˆæ‰©å±• | Mixtral, DeepSeek-V2 |\n",
    "| **é•¿ä¸Šä¸‹æ–‡** | å¤„ç†é•¿æ–‡æœ¬ | Claude, Gemini, Qwen-Long |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. æ–‡æœ¬å¤§æ¨¡å‹\n",
    "\n",
    "### 2.1 GPTç³»åˆ— (OpenAI)\n",
    "\n",
    "**GPT (Generative Pre-trained Transformer)** æ˜¯æœ€å…·å½±å“åŠ›çš„LLMç³»åˆ—ã€‚\n",
    "\n",
    "#### å‘å±•å†ç¨‹\n",
    "\n",
    "| æ¨¡å‹ | å‘å¸ƒæ—¶é—´ | å‚æ•°é‡ | å…³é”®ç‰¹æ€§ |\n",
    "|------|---------|--------|----------|\n",
    "| **GPT-1** | 2018.6 | 117M | é¦–æ¬¡è¯æ˜é¢„è®­ç»ƒ+å¾®è°ƒèŒƒå¼ |\n",
    "| **GPT-2** | 2019.2 | 1.5B | Zero-shotèƒ½åŠ›åˆç° |\n",
    "| **GPT-3** | 2020.5 | 175B | In-context learning, few-shot |\n",
    "| **InstructGPT** | 2022.1 | 1.3B-175B | RLHFå¯¹é½ |\n",
    "| **ChatGPT** | 2022.11 | ~175B | å¯¹è¯ä¼˜åŒ–ï¼Œå¼•çˆ†AIçƒ­æ½® |\n",
    "| **GPT-4** | 2023.3 | æœªå…¬å¼€ | å¤šæ¨¡æ€ï¼Œæ¨ç†èƒ½åŠ›é£è·ƒ |\n",
    "| **GPT-4 Turbo** | 2023.11 | æœªå…¬å¼€ | 128Kä¸Šä¸‹æ–‡ï¼Œæˆæœ¬é™ä½ |\n",
    "| **GPT-4o** | 2024.5 | æœªå…¬å¼€ | åŸç”Ÿå¤šæ¨¡æ€ï¼Œå®æ—¶äº¤äº’ |\n",
    "\n",
    "#### æ ¸å¿ƒæŠ€æœ¯\n",
    "\n",
    "1. **In-Context Learning**: é€šè¿‡ç¤ºä¾‹å­¦ä¹ ï¼Œæ— éœ€æ›´æ–°å‚æ•°\n",
    "2. **RLHF**: äººç±»åé¦ˆå¼ºåŒ–å­¦ä¹ ï¼Œå¯¹é½äººç±»åå¥½\n",
    "3. **System Message**: æ”¯æŒç³»ç»Ÿçº§æŒ‡ä»¤æ§åˆ¶\n",
    "4. **Function Calling**: å·¥å…·è°ƒç”¨èƒ½åŠ›\n",
    "\n",
    "#### åº”ç”¨åœºæ™¯\n",
    "\n",
    "- ğŸ’¬ å¯¹è¯åŠ©æ‰‹\n",
    "- ğŸ“ å†…å®¹åˆ›ä½œ\n",
    "- ğŸ’» ä»£ç ç”Ÿæˆï¼ˆCopilotï¼‰\n",
    "- ğŸ” ä¿¡æ¯æ£€ç´¢ä¸æ€»ç»“\n",
    "- ğŸ¯ ä»»åŠ¡è§„åˆ’ä¸å†³ç­–\n",
    "\n",
    "#### ç‰¹ç‚¹\n",
    "\n",
    "âœ… **ä¼˜åŠ¿**:\n",
    "- æ€§èƒ½é¡¶å°–ï¼Œå°¤å…¶æ˜¯GPT-4\n",
    "- APIç”Ÿæ€å®Œå–„\n",
    "- æŒç»­è¿­ä»£æ›´æ–°\n",
    "\n",
    "âŒ **åŠ£åŠ¿**:\n",
    "- é—­æºï¼Œæ— æ³•æœ¬åœ°éƒ¨ç½²\n",
    "- APIè°ƒç”¨æˆæœ¬è¾ƒé«˜\n",
    "- æ¨¡å‹æ¶æ„ç»†èŠ‚ä¸å…¬å¼€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 LLaMAç³»åˆ— (Meta)\n",
    "\n",
    "**LLaMA (Large Language Model Meta AI)** æ˜¯Metaå¼€æºçš„é«˜æ€§èƒ½LLMç³»åˆ—ï¼Œå¯¹å¼€æºç¤¾åŒºå½±å“æ·±è¿œã€‚\n",
    "\n",
    "#### ç‰ˆæœ¬å¯¹æ¯”\n",
    "\n",
    "| ç‰ˆæœ¬ | å‘å¸ƒæ—¶é—´ | å‚æ•°è§„æ ¼ | ä¸Šä¸‹æ–‡é•¿åº¦ | å…³é”®æ”¹è¿› |\n",
    "|------|---------|---------|-----------|----------|\n",
    "| **LLaMA 1** | 2023.2 | 7B, 13B, 33B, 65B | 2K | é«˜æ•ˆæ¶æ„ï¼Œæ€§èƒ½ä¼˜å¼‚ |\n",
    "| **LLaMA 2** | 2023.7 | 7B, 13B, 70B | 4K | å•†ç”¨å‹å¥½ï¼ŒChatç‰ˆæœ¬ |\n",
    "| **LLaMA 3** | 2024.4 | 8B, 70B | 8K | å¤šè¯­è¨€ï¼Œæ€§èƒ½å¤§å¹…æå‡ |\n",
    "| **LLaMA 3.1** | 2024.7 | 8B, 70B, 405B | 128K | è¶…é•¿ä¸Šä¸‹æ–‡ï¼Œå·¥å…·è°ƒç”¨ |\n",
    "| **LLaMA 3.2** | 2024.9 | 1B, 3B, 11B, 90B | 128K | å¤šæ¨¡æ€ï¼Œè½»é‡åŒ– |\n",
    "\n",
    "#### æ¶æ„ç‰¹ç‚¹\n",
    "\n",
    "1. **RMSNorm**: æ›¿ä»£LayerNormï¼Œæ›´é«˜æ•ˆ\n",
    "2. **SwiGLU**: æ›¿ä»£ä¼ ç»ŸFFNæ¿€æ´»å‡½æ•°\n",
    "3. **RoPE**: æ—‹è½¬ä½ç½®ç¼–ç ï¼Œæ”¯æŒé•¿ä¸Šä¸‹æ–‡å¤–æ¨\n",
    "4. **Grouped Query Attention (GQA)**: é™ä½æ¨ç†å†…å­˜\n",
    "\n",
    "#### æ•°æ®ä¸è®­ç»ƒ\n",
    "\n",
    "- **LLaMA 1**: 1.4T tokens\n",
    "- **LLaMA 2**: 2T tokens\n",
    "- **LLaMA 3**: 15T tokensï¼ˆå¤šè¯­è¨€æ•°æ®å æ¯”æå‡ï¼‰\n",
    "\n",
    "#### åº”ç”¨åœºæ™¯\n",
    "\n",
    "- ğŸ”¬ ç ”ç©¶åŸºåº§æ¨¡å‹\n",
    "- ğŸ­ ç§æœ‰åŒ–éƒ¨ç½²\n",
    "- ğŸ“ æ•™è‚²ä¸å­¦ä¹ \n",
    "- ğŸ”§ å¾®è°ƒå®šåˆ¶åŒ–\n",
    "\n",
    "#### è¡ç”Ÿæ¨¡å‹ç”Ÿæ€\n",
    "\n",
    "åŸºäºLLaMAçš„è‘—åè¡ç”Ÿ:\n",
    "- **Vicuna**: å¯¹è¯ä¼˜åŒ–\n",
    "- **Alpaca**: æ–¯å¦ç¦æŒ‡ä»¤å¾®è°ƒ\n",
    "- **WizardLM**: å¤æ‚æŒ‡ä»¤éµå¾ª\n",
    "- **Code LLaMA**: ä»£ç ä¸“ç”¨\n",
    "\n",
    "#### ç‰¹ç‚¹\n",
    "\n",
    "âœ… **ä¼˜åŠ¿**:\n",
    "- å¼€æºå¯å•†ç”¨ï¼ˆä»LLaMA 2å¼€å§‹ï¼‰\n",
    "- æ¶æ„å…ˆè¿›ï¼Œæ€§èƒ½ä¼˜ç§€\n",
    "- ç¤¾åŒºç”Ÿæ€ä¸°å¯Œ\n",
    "- å¯æœ¬åœ°éƒ¨ç½²\n",
    "\n",
    "âŒ **åŠ£åŠ¿**:\n",
    "- åŸç”Ÿå¤šè¯­è¨€èƒ½åŠ›ç›¸å¯¹å¼±ï¼ˆä¸»è¦è‹±è¯­ï¼‰\n",
    "- éœ€è¦è‡ªè¡Œéƒ¨ç½²å’Œä¼˜åŒ–"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Qwenç³»åˆ— (é˜¿é‡Œäº‘)\n",
    "\n",
    "**Qwen (é€šä¹‰åƒé—®)** æ˜¯é˜¿é‡Œäº‘å¼€æºçš„å¤šè¯­è¨€LLMç³»åˆ—ï¼Œå¯¹ä¸­æ–‡æ”¯æŒç‰¹åˆ«å‡ºè‰²ã€‚\n",
    "\n",
    "#### ç‰ˆæœ¬æ¼”è¿›\n",
    "\n",
    "| ç‰ˆæœ¬ | å‘å¸ƒæ—¶é—´ | å‚æ•°è§„æ ¼ | ä¸Šä¸‹æ–‡é•¿åº¦ | äº®ç‚¹ |\n",
    "|------|---------|---------|-----------|------|\n",
    "| **Qwen** | 2023.8 | 1.8B, 7B, 14B, 72B | 8K / 32K | é¦–ä¸ªä¸­æ–‡å¤§æ¨¡å‹å¼€æº |\n",
    "| **Qwen1.5** | 2024.2 | 0.5B-110B | 32K | æ¨¡å‹çŸ©é˜µå®Œæ•´ |\n",
    "| **Qwen2** | 2024.6 | 0.5B-72B | 128K | MoEæ¶æ„ï¼Œå¤šè¯­è¨€ |\n",
    "| **Qwen2.5** | 2024.9 | 0.5B-72B | 128K | çŸ¥è¯†æ›´æ–°ï¼Œæ€§èƒ½æå‡ |\n",
    "| **Qwen3** | 2025é¢„è®¡ | TBA | TBA | ä¸‹ä¸€ä»£æ¶æ„ |\n",
    "\n",
    "#### æ¶æ„äº®ç‚¹\n",
    "\n",
    "**Qwen2æ¶æ„**:\n",
    "- Decoder-only Transformer\n",
    "- GQA (Grouped Query Attention)\n",
    "- SwiGLUæ¿€æ´»\n",
    "- Dual Chunk Attentionï¼ˆé•¿æ–‡æœ¬ä¼˜åŒ–ï¼‰\n",
    "\n",
    "**Qwen2-MoE**:\n",
    "- 57Bæ€»å‚æ•°ï¼Œ14Bæ¿€æ´»å‚æ•°\n",
    "- 64ä¸ªä¸“å®¶ï¼ŒTop-4è·¯ç”±\n",
    "- æ€§èƒ½åª²ç¾70Bç¨ å¯†æ¨¡å‹\n",
    "\n",
    "#### è®­ç»ƒæ•°æ®\n",
    "\n",
    "- **æ•°æ®é‡**: 7T+ tokensï¼ˆQwen2.5ï¼‰\n",
    "- **å¤šè¯­è¨€**: 29ç§è¯­è¨€ï¼Œä¸­æ–‡å æ¯”é«˜\n",
    "- **æ•°æ®è´¨é‡**: ä¸¥æ ¼æ¸…æ´—å’Œå»é‡\n",
    "- **çŸ¥è¯†æˆªæ­¢**: 2024å¹´7æœˆï¼ˆQwen2.5ï¼‰\n",
    "\n",
    "#### æ¨¡å‹çŸ©é˜µ\n",
    "\n",
    "Qwenæä¾›å®Œæ•´çš„æ¨¡å‹å°ºå¯¸æ¢¯åº¦:\n",
    "\n",
    "```\n",
    "0.5B â†’ è¾¹ç¼˜è®¾å¤‡ï¼Œæ‰‹æœºç«¯\n",
    "1.5B â†’ è½»é‡çº§åº”ç”¨\n",
    "7B   â†’ ä¸ªäººç”µè„‘ï¼Œå°å‹æœåŠ¡å™¨\n",
    "14B  â†’ ä¸­å‹æœåŠ¡å™¨\n",
    "32B  â†’ é«˜æ€§èƒ½åœºæ™¯\n",
    "72B  â†’ é¡¶çº§æ€§èƒ½\n",
    "```\n",
    "\n",
    "#### åº”ç”¨åœºæ™¯\n",
    "\n",
    "- ğŸ‡¨ğŸ‡³ ä¸­æ–‡åº”ç”¨ï¼ˆè¯—è¯ã€æ–‡è¨€æ–‡ã€æ–¹è¨€ï¼‰\n",
    "- ğŸ’¼ ä¼ä¸šç§æœ‰åŒ–éƒ¨ç½²\n",
    "- ğŸ“± ç«¯ä¾§æ¨¡å‹ï¼ˆQwen-0.5Bï¼‰\n",
    "- ğŸŒ å¤šè¯­è¨€åœºæ™¯\n",
    "\n",
    "#### æ€§èƒ½è¡¨ç°\n",
    "\n",
    "Qwen2.5åœ¨å¤šä¸ªåŸºå‡†ä¸Šè¡¨ç°ä¼˜å¼‚:\n",
    "- **MMLU**: 85.5 (Qwen2.5-72B)\n",
    "- **HumanEval**: 86.0 (ä»£ç èƒ½åŠ›)\n",
    "- **C-Eval**: 90.3 (ä¸­æ–‡ç†è§£)\n",
    "\n",
    "#### ç‰¹ç‚¹\n",
    "\n",
    "âœ… **ä¼˜åŠ¿**:\n",
    "- å¼€æºå¯å•†ç”¨ï¼ˆApache 2.0ï¼‰\n",
    "- ä¸­æ–‡èƒ½åŠ›é¡¶å°–\n",
    "- æ¨¡å‹è§„æ ¼é½å…¨\n",
    "- æŒç»­å¿«é€Ÿè¿­ä»£\n",
    "- å®Œå–„çš„å·¥å…·é“¾ï¼ˆvLLM, llama.cppç­‰ï¼‰\n",
    "\n",
    "âŒ **åŠ£åŠ¿**:\n",
    "- è‹±æ–‡èƒ½åŠ›ç•¥é€ŠäºGPT-4\n",
    "- éƒ¨åˆ†é«˜çº§æ¨ç†ä»»åŠ¡ä»æœ‰å·®è·"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 å…¶ä»–ä¸»æµæ¨¡å‹\n",
    "\n",
    "#### Gemini (Google)\n",
    "\n",
    "- **Gemini 1.0**: ä¸‰ä¸ªç‰ˆæœ¬ï¼ˆUltra, Pro, Nanoï¼‰\n",
    "- **Gemini 1.5**: è¶…é•¿ä¸Šä¸‹æ–‡ï¼ˆ1M-2M tokensï¼‰\n",
    "- **ç‰¹ç‚¹**: åŸç”Ÿå¤šæ¨¡æ€ï¼ŒTPUä¼˜åŒ–\n",
    "\n",
    "#### Claude (Anthropic)\n",
    "\n",
    "- **Claude 3ç³»åˆ—**: Opusï¼ˆæœ€å¼ºï¼‰, Sonnetï¼ˆå¹³è¡¡ï¼‰, Haikuï¼ˆå¿«é€Ÿï¼‰\n",
    "- **ç‰¹ç‚¹**: å®‰å…¨æ€§å¼ºï¼Œé•¿æ–‡æœ¬ï¼ˆ200Kï¼‰ï¼Œå¯æ§æ€§å¥½\n",
    "- **Constitutional AI**: åŸºäºåŸåˆ™çš„å¯¹é½æ–¹æ³•\n",
    "\n",
    "#### Baichuan (ç™¾å·æ™ºèƒ½)\n",
    "\n",
    "- **Baichuan 2**: 7B, 13B\n",
    "- **ç‰¹ç‚¹**: ä¸­æ–‡ä¼˜åŒ–ï¼Œå¼€æº\n",
    "\n",
    "#### ChatGLM (æ™ºè°±AI)\n",
    "\n",
    "- **ChatGLM3**: 6B\n",
    "- **GLM-4**: 9B\n",
    "- **ç‰¹ç‚¹**: åŒè¯­ä¼˜åŒ–ï¼Œå·¥å…·è°ƒç”¨ï¼ŒCode Interpreter\n",
    "\n",
    "#### Yi (é›¶ä¸€ä¸‡ç‰©)\n",
    "\n",
    "- **Yi-34B**: å¼€æºï¼Œæ€§èƒ½ä¼˜å¼‚\n",
    "- **Yi-VL**: å¤šæ¨¡æ€ç‰ˆæœ¬\n",
    "\n",
    "#### Mistral (Mistral AI)\n",
    "\n",
    "- **Mistral 7B**: å°è€Œå¼º\n",
    "- **Mixtral 8x7B**: MoEæ¶æ„ï¼Œ47Bå‚æ•°ï¼Œ13Bæ¿€æ´»\n",
    "- **Mixtral 8x22B**: æ›´å¤§ç‰ˆæœ¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ä¸»æµLLMæ€§èƒ½å¯¹æ¯”å¯è§†åŒ–ï¼ˆåŸºäºå…¬å¼€benchmarkï¼‰\nmodels = ['GPT-4', 'Claude-3\\nOpus', 'Gemini-1.5\\nPro', 'Qwen2.5\\n72B', 'LLaMA-3.1\\n70B', 'Mixtral\\n8x22B']\nmmlu = [86.4, 86.8, 85.9, 85.5, 83.6, 77.8]  # MMLUåˆ†æ•°\nhumaneval = [67.0, 84.9, 71.9, 86.0, 80.5, 75.8]  # HumanEvalä»£ç åˆ†æ•°\ngsm8k = [92.0, 95.0, 90.8, 91.6, 89.0, 83.7]  # GSM8Kæ•°å­¦åˆ†æ•°\n\nx = np.arange(len(models))\nwidth = 0.25\n\nfig, ax = plt.subplots(figsize=(14, 6))\nrects1 = ax.bar(x - width, mmlu, width, label='MMLU (General Knowledge)', color='#FF6B6B')\nrects2 = ax.bar(x, humaneval, width, label='HumanEval (Coding)', color='#4ECDC4')\nrects3 = ax.bar(x + width, gsm8k, width, label='GSM8K (Math)', color='#95E1D3')\n\nax.set_xlabel('Model', fontsize=12)\nax.set_ylabel('Score', fontsize=12)\nax.set_title('Mainstream LLM Performance Comparison (Multiple Benchmarks)', fontsize=14, pad=20)\nax.set_xticks(x)\nax.set_xticklabels(models)\nax.legend(fontsize=10)\nax.grid(True, alpha=0.3, axis='y')\nax.set_ylim(0, 100)\n\n# æ·»åŠ æ•°å€¼æ ‡ç­¾\ndef autolabel(rects):\n    for rect in rects:\n        height = rect.get_height()\n        ax.annotate(f'{height:.1f}',\n                   xy=(rect.get_x() + rect.get_width() / 2, height),\n                   xytext=(0, 3),\n                   textcoords=\"offset points\",\n                   ha='center', va='bottom', fontsize=8)\n\nautolabel(rects1)\nautolabel(rects2)\nautolabel(rects3)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"Note: Data is based on public benchmarks; actual performance may vary depending on test conditions\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. æ€è€ƒæ¨¡å‹ (Reasoning Models)\n",
    "\n",
    "æ€è€ƒæ¨¡å‹æ˜¯ä¸“é—¨é’ˆå¯¹å¤æ‚æ¨ç†ä»»åŠ¡ä¼˜åŒ–çš„LLM,èƒ½å¤Ÿå±•ç°\"æ€è€ƒè¿‡ç¨‹\"ã€‚\n",
    "\n",
    "### 3.1 DeepSeekç³»åˆ—\n",
    "\n",
    "#### DeepSeek-V2 (2024.5)\n",
    "\n",
    "**æ¶æ„åˆ›æ–°**:\n",
    "- **MLA (Multi-head Latent Attention)**: é™ä½KV Cache\n",
    "- **DeepSeekMoE**: æ›´é«˜æ•ˆçš„MoEæ¶æ„\n",
    "  - æ€»å‚æ•°: 236B\n",
    "  - æ¿€æ´»å‚æ•°: 21B\n",
    "  - ä¸“å®¶æ•°: 160ä¸ª\n",
    "  - Top-K: 6\n",
    "\n",
    "**ç‰¹ç‚¹**:\n",
    "- è®­ç»ƒæˆæœ¬ä½ï¼ˆç›¸æ¯”åŒç­‰æ€§èƒ½æ¨¡å‹ï¼‰\n",
    "- æ¨ç†æ•ˆç‡é«˜\n",
    "- å¼€æºå¯å•†ç”¨\n",
    "\n",
    "#### DeepSeek-R1 (2025.1)\n",
    "\n",
    "**æ ¸å¿ƒèƒ½åŠ›**: å¼ºåŒ–å­¦ä¹ æ¨ç†\n",
    "\n",
    "```\n",
    "é—®é¢˜ â†’ æ€è€ƒè¿‡ç¨‹ â†’ ç­”æ¡ˆ\n",
    "       (Chain-of-Thought)\n",
    "```\n",
    "\n",
    "**æŠ€æœ¯äº®ç‚¹**:\n",
    "1. **RL-driven Reasoning**: é€šè¿‡å¼ºåŒ–å­¦ä¹ è®­ç»ƒæ¨ç†èƒ½åŠ›\n",
    "2. **å¯éªŒè¯æ€§**: æ¨ç†æ­¥éª¤å¯æ£€æŸ¥\n",
    "3. **è‡ªæˆ‘çº é”™**: èƒ½å¤Ÿå‘ç°å¹¶ä¿®æ­£é”™è¯¯\n",
    "\n",
    "**æ€§èƒ½è¡¨ç°**:\n",
    "- **AIME 2024**: 79.8% (æ•°å­¦ç«èµ›)\n",
    "- **Codeforces**: 96.3% (ç¼–ç¨‹ç«èµ›)\n",
    "- **MATH**: 97.3% (é«˜ä¸­æ•°å­¦)\n",
    "\n",
    "**åº”ç”¨åœºæ™¯**:\n",
    "- ğŸ§® æ•°å­¦é—®é¢˜æ±‚è§£\n",
    "- ğŸ§ª ç§‘å­¦æ¨ç†\n",
    "- ğŸ’» ç®—æ³•è®¾è®¡\n",
    "- ğŸ¯ å¤šæ­¥éª¤è§„åˆ’\n",
    "\n",
    "#### ç‰¹ç‚¹\n",
    "\n",
    "âœ… **ä¼˜åŠ¿**:\n",
    "- æ¨ç†èƒ½åŠ›é¡¶å°–\n",
    "- æˆæœ¬æ•ˆç›Šé«˜\n",
    "- å¼€æºç¤¾åŒºæ´»è·ƒ\n",
    "\n",
    "âŒ **å±€é™**:\n",
    "- æ¨ç†é€Ÿåº¦è¾ƒæ…¢ï¼ˆéœ€è¦ç”Ÿæˆæ€è€ƒè¿‡ç¨‹ï¼‰\n",
    "- å¯¹ç®€å•é—®é¢˜å¯èƒ½è¿‡åº¦æ€è€ƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Qwenæ€è€ƒæ¨¡å‹\n",
    "\n",
    "#### QwQ-32B-Preview (2024.11)\n",
    "\n",
    "Qwenå›¢é˜Ÿå‘å¸ƒçš„æ€è€ƒæ¨¡å‹ï¼Œå±•ç°å¼ºå¤§çš„æ¨ç†èƒ½åŠ›ã€‚\n",
    "\n",
    "**æ ¸å¿ƒç‰¹æ€§**:\n",
    "- 32Bå‚æ•°ï¼ŒåŸºäºQwen2.5æ¶æ„\n",
    "- 32Kä¸Šä¸‹æ–‡çª—å£\n",
    "- é•¿æ€è€ƒé“¾ï¼ˆå¯è¾¾æ•°åƒtokensï¼‰\n",
    "\n",
    "**æŠ€æœ¯æ–¹æ³•**:\n",
    "- å¼ºåŒ–å­¦ä¹  + æ¨ç†è®­ç»ƒ\n",
    "- Self-playè®­ç»ƒç­–ç•¥\n",
    "- å¥–åŠ±æ¨¡å‹ä¼˜åŒ–\n",
    "\n",
    "**æ€§èƒ½**:\n",
    "- **GPQA**: 65.2% (ç ”ç©¶ç”Ÿçº§åˆ«ç§‘å­¦é—®é¢˜)\n",
    "- **MATH-500**: 90.6%\n",
    "- **LiveCodeBench**: 50.0%\n",
    "\n",
    "#### ç‰¹ç‚¹\n",
    "\n",
    "âœ… **ä¼˜åŠ¿**:\n",
    "- ä¸­è‹±æ–‡æ¨ç†èƒ½åŠ›å¼º\n",
    "- å¼€æºå¯ç ”ç©¶\n",
    "- å‚æ•°é‡ç›¸å¯¹å°ï¼ˆ32Bï¼‰\n",
    "\n",
    "âŒ **å±€é™**:\n",
    "- Previewç‰ˆæœ¬ï¼Œä»åœ¨è¿­ä»£\n",
    "- éƒ¨åˆ†åœºæ™¯ä¸‹ä¼š\"æƒ³å¤ªå¤š\"\n",
    "\n",
    "### 3.3 å…¶ä»–æ€è€ƒæ¨¡å‹\n",
    "\n",
    "#### o1ç³»åˆ— (OpenAI)\n",
    "\n",
    "- **o1-preview**, **o1-mini** (2024.9)\n",
    "- é—­æºï¼ŒAPIè®¿é—®\n",
    "- æ¨ç†èƒ½åŠ›æå¼ºï¼Œå°¤å…¶æ˜¯STEMé¢†åŸŸ\n",
    "- æˆæœ¬è¾ƒé«˜\n",
    "\n",
    "### 3.4 æ€è€ƒæ¨¡å‹å¯¹æ¯”\n",
    "\n",
    "| æ¨¡å‹ | å‚æ•°é‡ | å¼€æº | æ¨ç†é€Ÿåº¦ | æœ€ä½³åœºæ™¯ |\n",
    "|------|--------|------|---------|----------|\n",
    "| **o1** | æœªçŸ¥ | âŒ | æ…¢ | STEMé—®é¢˜ï¼Œç¼–ç¨‹ç«èµ› |\n",
    "| **DeepSeek-R1** | 671B | âœ… | ä¸­ | æ•°å­¦æ¨ç†ï¼Œç®—æ³•è®¾è®¡ |\n",
    "| **QwQ-32B** | 32B | âœ… | ä¸­ | ä¸­æ–‡æ¨ç†ï¼Œç§‘å­¦é—®ç­” |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ä»£ç æ¨¡å‹\n",
    "\n",
    "ä»£ç æ¨¡å‹æ˜¯ä¸“é—¨é’ˆå¯¹ç¼–ç¨‹ä»»åŠ¡ä¼˜åŒ–çš„LLMã€‚\n",
    "\n",
    "### 4.1 Qwen-Coderç³»åˆ—\n",
    "\n",
    "#### Qwen2.5-Coder (2024.11)\n",
    "\n",
    "**è§„æ ¼**:\n",
    "- æ¨¡å‹å°ºå¯¸: 1.5B, 7B, 14B, 32B\n",
    "- ä¸Šä¸‹æ–‡: 128K\n",
    "- æ”¯æŒ92ç§ç¼–ç¨‹è¯­è¨€\n",
    "\n",
    "**è®­ç»ƒæ•°æ®**:\n",
    "- 5.5T tokensä»£ç æ•°æ®\n",
    "- åŒ…å«ä»£ç åº“ã€æ–‡æ¡£ã€é—®ç­”ç­‰\n",
    "- é«˜è´¨é‡ä»£ç ä»“åº“ä¼˜å…ˆ\n",
    "\n",
    "**èƒ½åŠ›çŸ©é˜µ**:\n",
    "\n",
    "```\n",
    "ä»£ç ç”Ÿæˆ â†’ å‡½æ•°/ç±»/é¡¹ç›®çº§åˆ«ä»£ç \n",
    "ä»£ç è¡¥å…¨ â†’ IDEé›†æˆï¼Œå®æ—¶è¡¥å…¨\n",
    "ä»£ç ç†è§£ â†’ è§£é‡Šã€æ³¨é‡Šã€æ–‡æ¡£ç”Ÿæˆ\n",
    "ä»£ç è°ƒè¯• â†’ æŸ¥æ‰¾bugï¼Œä¿®å¤ä»£ç \n",
    "ä»£ç ç¿»è¯‘ â†’ è·¨è¯­è¨€ä»£ç è½¬æ¢\n",
    "ä»£ç ä¼˜åŒ– â†’ æ€§èƒ½ä¼˜åŒ–ï¼Œé‡æ„å»ºè®®\n",
    "```\n",
    "\n",
    "**æ€§èƒ½è¡¨ç°**:\n",
    "\n",
    "| åŸºå‡† | Qwen2.5-Coder-32B | GPT-4o | Claude-3.5 |\n",
    "|------|------------------|---------|------------|\n",
    "| HumanEval | 92.7 | 90.2 | 92.0 |\n",
    "| MBPP | 88.2 | 87.3 | 86.0 |\n",
    "| LiveCodeBench | 65.3 | 53.3 | 60.5 |\n",
    "\n",
    "**ç‰¹è‰²åŠŸèƒ½**:\n",
    "\n",
    "1. **Repository-Level**: ç†è§£æ•´ä¸ªä»£ç ä»“åº“\n",
    "2. **Long Context**: å¤„ç†å¤§å‹é¡¹ç›®æ–‡ä»¶\n",
    "3. **Artifacts**: æ”¯æŒç”ŸæˆHTML/Reactç­‰å¯äº¤äº’ç»„ä»¶\n",
    "4. **Multi-Language**: ä¼˜ç§€çš„è·¨è¯­è¨€èƒ½åŠ›\n",
    "\n",
    "**åº”ç”¨åœºæ™¯**:\n",
    "\n",
    "- ğŸ’» AIç¼–ç¨‹åŠ©æ‰‹\n",
    "- ğŸ”§ ä»£ç å®¡æŸ¥å·¥å…·\n",
    "- ğŸ“š è‡ªåŠ¨åŒ–æ–‡æ¡£ç”Ÿæˆ\n",
    "- ğŸ“ ç¼–ç¨‹æ•™è‚²\n",
    "- ğŸ› Bugæ£€æµ‹ä¸ä¿®å¤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 å…¶ä»–ä»£ç æ¨¡å‹\n",
    "\n",
    "#### GitHub Copilot / Codex (OpenAI)\n",
    "\n",
    "- åŸºäºGPTç³»åˆ—\n",
    "- IDEæ·±åº¦é›†æˆï¼ˆVS Code, JetBrainsç­‰ï¼‰\n",
    "- å®æ—¶ä»£ç è¡¥å…¨\n",
    "\n",
    "#### Code LLaMA (Meta)\n",
    "\n",
    "- åŸºäºLLaMA 2å¾®è°ƒ\n",
    "- ä¸‰ä¸ªç‰ˆæœ¬: Base, Python, Instruct\n",
    "- å‚æ•°é‡: 7B, 13B, 34B\n",
    "- å¼€æºå¯å•†ç”¨\n",
    "\n",
    "#### StarCoder (Hugging Face)\n",
    "\n",
    "- StarCoder2: 3B, 7B, 15B\n",
    "- è®­ç»ƒæ•°æ®: The Stack v2 (600B+ tokens)\n",
    "- 80+ç¼–ç¨‹è¯­è¨€\n",
    "- å¼€æºå¯å•†ç”¨\n",
    "\n",
    "#### DeepSeek-Coder (DeepSeek)\n",
    "\n",
    "- DeepSeek-Coder-V2: 16B, 236B\n",
    "- æ”¯æŒ338ç§ç¼–ç¨‹è¯­è¨€\n",
    "- Fill-in-the-Middleèƒ½åŠ›\n",
    "- å¼€æº\n",
    "\n",
    "#### ä»£ç æ¨¡å‹å¯¹æ¯”\n",
    "\n",
    "| æ¨¡å‹ | å‚æ•°é‡ | å¼€æº | ä¸­æ–‡ | ä»“åº“çº§ç†è§£ |\n",
    "|------|--------|------|------|------------|\n",
    "| **Qwen2.5-Coder** | 1.5B-32B | âœ… | âœ… | âœ… |\n",
    "| **GPT-4o** | æœªçŸ¥ | âŒ | âœ… | âœ… |\n",
    "| **Claude-3.5** | æœªçŸ¥ | âŒ | âœ… | âœ… |\n",
    "| **Code LLaMA** | 7B-34B | âœ… | âŒ | âŒ |\n",
    "| **DeepSeek-Coder-V2** | 16B-236B | âœ… | âœ… | âœ… |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. å¤šæ¨¡æ€æ¨¡å‹\n",
    "\n",
    "å¤šæ¨¡æ€æ¨¡å‹èƒ½å¤Ÿç†è§£å’Œç”Ÿæˆå¤šç§æ¨¡æ€çš„æ•°æ®ï¼ˆæ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘ã€è§†é¢‘ï¼‰ã€‚\n",
    "\n",
    "### 5.1 Qwen-VLç³»åˆ—\n",
    "\n",
    "#### Qwen2-VL (2024.8)\n",
    "\n",
    "**æ¨¡å‹è§„æ ¼**:\n",
    "- Qwen2-VL-2B: è½»é‡çº§\n",
    "- Qwen2-VL-7B: å¹³è¡¡ç‰ˆ\n",
    "- Qwen2-VL-72B: æ——èˆ°ç‰ˆ\n",
    "\n",
    "**æ ¸å¿ƒèƒ½åŠ›**:\n",
    "\n",
    "1. **å›¾åƒç†è§£**\n",
    "   - å›¾åƒæè¿°ç”Ÿæˆ\n",
    "   - è§†è§‰é—®ç­”ï¼ˆVQAï¼‰\n",
    "   - OCRæ–‡å­—è¯†åˆ«\n",
    "   - å›¾è¡¨åˆ†æ\n",
    "\n",
    "2. **è§†é¢‘ç†è§£**\n",
    "   - é•¿è§†é¢‘ç†è§£ï¼ˆ20åˆ†é’Ÿ+ï¼‰\n",
    "   - è§†é¢‘é—®ç­”\n",
    "   - æ—¶åºæ¨ç†\n",
    "\n",
    "3. **å¤šå›¾äº¤äº’**\n",
    "   - å¯¹æ¯”å¤šå¼ å›¾ç‰‡\n",
    "   - å›¾ç‰‡é—´å…³ç³»ç†è§£\n",
    "\n",
    "4. **Agentèƒ½åŠ›**\n",
    "   - GUIå¯¼èˆª\n",
    "   - å±å¹•ç†è§£\n",
    "   - è‡ªåŠ¨åŒ–æ“ä½œ\n",
    "\n",
    "**æŠ€æœ¯äº®ç‚¹**:\n",
    "\n",
    "- **Native Dynamic Resolution**: åŠ¨æ€åˆ†è¾¨ç‡æ”¯æŒ\n",
    "- **Naive Dynamic Resolution**: è‡ªé€‚åº”å›¾åƒåˆ†å—\n",
    "- **M-RoPE**: å¤šæ¨¡æ€æ—‹è½¬ä½ç½®ç¼–ç \n",
    "- **é•¿ä¸Šä¸‹æ–‡**: 32K tokens\n",
    "\n",
    "**æ€§èƒ½**:\n",
    "\n",
    "| åŸºå‡† | Qwen2-VL-72B | GPT-4o | Gemini-1.5 Pro |\n",
    "|------|-------------|---------|----------------|\n",
    "| **MMBench** | 86.5 | 83.4 | 81.3 |\n",
    "| **DocVQA** | 96.5 | 92.8 | 93.1 |\n",
    "| **TextVQA** | 84.3 | 78.0 | 78.7 |\n",
    "\n",
    "**åº”ç”¨åœºæ™¯**:\n",
    "\n",
    "- ğŸ“· å›¾åƒæè¿°ä¸æ ‡æ³¨\n",
    "- ğŸ“Š æ•°æ®å¯è§†åŒ–åˆ†æ\n",
    "- ğŸ¬ è§†é¢‘å†…å®¹ç†è§£\n",
    "- ğŸ–¥ï¸ å±å¹•æˆªå›¾ç†è§£\n",
    "- ğŸ¥ åŒ»ç–—å½±åƒåˆ†æ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 GLM-4V (æ™ºè°±AI)\n",
    "\n",
    "**GLM-4V** æ˜¯æ™ºè°±AIçš„å¤šæ¨¡æ€æ——èˆ°æ¨¡å‹ã€‚\n",
    "\n",
    "#### æ ¸å¿ƒèƒ½åŠ›\n",
    "\n",
    "- **å›¾æ–‡ç†è§£**: OCR, å›¾è¡¨, å…¬å¼è¯†åˆ«\n",
    "- **ä¸­æ–‡ä¼˜åŠ¿**: ä¸­æ–‡åœºæ™¯ä¼˜åŒ–\n",
    "- **é•¿å›¾æ”¯æŒ**: é«˜åˆ†è¾¨ç‡é•¿å›¾ç†è§£\n",
    "\n",
    "#### ç‰¹ç‚¹\n",
    "\n",
    "âœ… ä¸­æ–‡å›¾åƒç†è§£ä¼˜ç§€  \n",
    "âœ… æ”¯æŒæ•°å­¦å…¬å¼ã€è¡¨æ ¼è¯†åˆ«  \n",
    "âœ… APIè°ƒç”¨æ–¹ä¾¿  \n",
    "\n",
    "### 5.3 å…¶ä»–å¤šæ¨¡æ€æ¨¡å‹\n",
    "\n",
    "#### GPT-4V / GPT-4o (OpenAI)\n",
    "\n",
    "- **GPT-4V**: è§†è§‰èƒ½åŠ›åŠ æŒ\n",
    "- **GPT-4o**: åŸç”Ÿå¤šæ¨¡æ€ï¼ˆæ–‡æœ¬+å›¾åƒ+éŸ³é¢‘ï¼‰\n",
    "- å®æ—¶è¯­éŸ³äº¤äº’\n",
    "- æ€§èƒ½é¡¶å°–ä½†é—­æº\n",
    "\n",
    "#### Gemini 1.5 Pro (Google)\n",
    "\n",
    "- åŸç”Ÿå¤šæ¨¡æ€\n",
    "- è¶…é•¿ä¸Šä¸‹æ–‡ï¼ˆ1M tokensï¼‰\n",
    "- æ”¯æŒè§†é¢‘ã€éŸ³é¢‘ã€å›¾åƒ\n",
    "\n",
    "#### Claude 3 Opus/Sonnet (Anthropic)\n",
    "\n",
    "- è§†è§‰ç†è§£èƒ½åŠ›å¼º\n",
    "- æ–‡æ¡£åˆ†æä¼˜ç§€\n",
    "- å®‰å…¨æ€§é«˜\n",
    "\n",
    "#### LLaVA (å¼€æº)\n",
    "\n",
    "- åŸºäºLLaMAçš„å¤šæ¨¡æ€æ¨¡å‹\n",
    "- è½»é‡çº§\n",
    "- é€‚åˆç ”ç©¶å’Œå­¦ä¹ \n",
    "\n",
    "#### CogVLM / CogAgent (æ™ºè°±AI)\n",
    "\n",
    "- å¼€æºå¤šæ¨¡æ€æ¨¡å‹\n",
    "- CogAgent: GUI Agentä¸“ç”¨\n",
    "\n",
    "### 5.4 å¤šæ¨¡æ€æ¨¡å‹å¯¹æ¯”\n",
    "\n",
    "| æ¨¡å‹ | å›¾åƒ | è§†é¢‘ | éŸ³é¢‘ | å¼€æº | ä¸­æ–‡ |\n",
    "|------|------|------|------|------|------|\n",
    "| **Qwen2-VL** | âœ… | âœ… | âŒ | âœ… | âœ… |\n",
    "| **GPT-4o** | âœ… | âœ… | âœ… | âŒ | âœ… |\n",
    "| **Gemini-1.5** | âœ… | âœ… | âœ… | âŒ | âœ… |\n",
    "| **GLM-4V** | âœ… | âŒ | âŒ | âŒ | âœ… |\n",
    "| **LLaVA** | âœ… | âŒ | âŒ | âœ… | âš ï¸ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# å¤šæ¨¡æ€æ¨¡å‹èƒ½åŠ›é›·è¾¾å›¾\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ncategories = ['Image\\nUnderstanding', 'Video\\nUnderstanding', 'Document\\nOCR', 'GUI\\nInteraction', 'Multi-Image\\nComparison', 'Chinese\\nAbility']\nnum_vars = len(categories)\n\n# å„æ¨¡å‹åœ¨ä¸åŒç»´åº¦çš„èƒ½åŠ›ï¼ˆä¸»è§‚è¯„åˆ†ï¼Œä»…ä¾›å‚è€ƒï¼‰\nqwen2_vl = [95, 90, 95, 90, 95, 98]\ngpt4o = [95, 85, 90, 85, 90, 85]\ngemini = [90, 92, 88, 80, 85, 80]\nglm4v = [90, 70, 92, 75, 80, 95]\n\n# è®¡ç®—è§’åº¦\nangles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()\nangles += angles[:1]  # é—­åˆ\n\n# é—­åˆæ•°æ®\nqwen2_vl += qwen2_vl[:1]\ngpt4o += gpt4o[:1]\ngemini += gemini[:1]\nglm4v += glm4v[:1]\n\n# ç»˜å›¾\nfig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(polar=True))\n\nax.plot(angles, qwen2_vl, 'o-', linewidth=2, label='Qwen2-VL', color='#FF6B6B')\nax.fill(angles, qwen2_vl, alpha=0.15, color='#FF6B6B')\n\nax.plot(angles, gpt4o, 'o-', linewidth=2, label='GPT-4o', color='#4ECDC4')\nax.fill(angles, gpt4o, alpha=0.15, color='#4ECDC4')\n\nax.plot(angles, gemini, 'o-', linewidth=2, label='Gemini-1.5', color='#95E1D3')\nax.fill(angles, gemini, alpha=0.15, color='#95E1D3')\n\nax.plot(angles, glm4v, 'o-', linewidth=2, label='GLM-4V', color='#F7DC6F')\nax.fill(angles, glm4v, alpha=0.15, color='#F7DC6F')\n\nax.set_xticks(angles[:-1])\nax.set_xticklabels(categories, fontsize=11)\nax.set_ylim(0, 100)\nax.set_yticks([20, 40, 60, 80, 100])\nax.set_yticklabels(['20', '40', '60', '80', '100'], fontsize=9)\nax.grid(True, linestyle='--', alpha=0.7)\n\nax.set_title('Multimodal Model Capability Comparison (Subjective Ratings)', fontsize=14, pad=30)\nax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1), fontsize=11)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"Note: These ratings are relative comparisons for reference only\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. æ¨¡å‹é€‰æ‹©æŒ‡å—\n",
    "\n",
    "æ ¹æ®ä¸åŒçš„éœ€æ±‚åœºæ™¯,é€‰æ‹©åˆé€‚çš„å¤§è¯­è¨€æ¨¡å‹:\n",
    "\n",
    "### 6.1 æŒ‰åº”ç”¨åœºæ™¯é€‰æ‹©\n",
    "\n",
    "#### ğŸ’¬ é€šç”¨å¯¹è¯åŠ©æ‰‹\n",
    "- **é—­æºé¦–é€‰**: GPT-4o, Claude-3-Opus\n",
    "- **å¼€æºé¦–é€‰**: Qwen2.5-72B, LLaMA-3.1-70B\n",
    "- **æ€§ä»·æ¯”**: Qwen2.5-14B, Mistral-7B\n",
    "\n",
    "#### ğŸ‡¨ğŸ‡³ ä¸­æ–‡åº”ç”¨\n",
    "- **æœ€ä½³**: Qwen2.5ç³»åˆ—\n",
    "- **å¤‡é€‰**: GLM-4, Baichuan2\n",
    "\n",
    "#### ğŸ’» ç¼–ç¨‹åŠ©æ‰‹\n",
    "- **ä¸“ä¸š**: Qwen2.5-Coder-32B, DeepSeek-Coder-V2\n",
    "- **é€šç”¨**: GPT-4o, Claude-3.5-Sonnet\n",
    "\n",
    "#### ğŸ§® æ•°å­¦æ¨ç†\n",
    "- **é¡¶çº§**: DeepSeek-R1, o1\n",
    "- **å¼€æº**: QwQ-32B, Qwen2.5-Math\n",
    "\n",
    "#### ğŸ“· å›¾åƒç†è§£\n",
    "- **å¼€æº**: Qwen2-VL-72B\n",
    "- **é—­æº**: GPT-4o, Gemini-1.5-Pro\n",
    "- **ä¸­æ–‡**: GLM-4V\n",
    "\n",
    "#### ğŸ“„ é•¿æ–‡æ¡£å¤„ç†\n",
    "- **è¶…é•¿**: Gemini-1.5-Pro (2M), Claude-3-Opus (200K)\n",
    "- **å¼€æº**: Qwen2.5-72B (128K)\n",
    "\n",
    "### 6.2 æŒ‰éƒ¨ç½²æ–¹å¼é€‰æ‹©\n",
    "\n",
    "#### â˜ï¸ APIè°ƒç”¨ï¼ˆäº‘ç«¯ï¼‰\n",
    "```\n",
    "æ€§èƒ½ä¼˜å…ˆ â†’ GPT-4o, Claude-3-Opus\n",
    "æˆæœ¬ä¼˜å…ˆ â†’ Qwen API, DeepSeek API\n",
    "```\n",
    "\n",
    "#### ğŸ¢ ç§æœ‰åŒ–éƒ¨ç½²\n",
    "```\n",
    "æœåŠ¡å™¨ï¼ˆå¤šå¡ï¼‰â†’ Qwen2.5-72B, LLaMA-3.1-70B\n",
    "å·¥ä½œç«™ï¼ˆå•å¡ï¼‰â†’ Qwen2.5-14B, Mistral-7B\n",
    "ä¸ªäººç”µè„‘ â†’ Qwen2.5-7B, LLaMA-3.1-8B\n",
    "```\n",
    "\n",
    "#### ğŸ“± è¾¹ç¼˜è®¾å¤‡\n",
    "```\n",
    "æ‰‹æœºç«¯ â†’ Qwen2.5-0.5B, Gemini-Nano\n",
    "åµŒå…¥å¼ â†’ Qwen2.5-1.5B\n",
    "```\n",
    "\n",
    "### 6.3 æŒ‰èµ„æºçº¦æŸé€‰æ‹©\n",
    "\n",
    "| GPUæ˜¾å­˜ | æ¨èæ¨¡å‹ï¼ˆFP16ï¼‰ |\n",
    "|---------|------------------|\n",
    "| **8GB** | Qwen2.5-1.5B, LLaMA-3.2-3B (é‡åŒ–) |\n",
    "| **16GB** | Qwen2.5-7B, Mistral-7B (é‡åŒ–å¯åˆ°14B) |\n",
    "| **24GB** | Qwen2.5-14B, LLaMA-3.1-8B (FP16) |\n",
    "| **40GB** | Qwen2.5-32B (é‡åŒ–), LLaMA-3.1-70B (é‡åŒ–) |\n",
    "| **80GB** | Qwen2.5-72B, LLaMA-3.1-70B |\n",
    "| **å¤šå¡** | ä»»ä½•æ¨¡å‹ï¼ˆé€šè¿‡å¼ é‡å¹¶è¡Œï¼‰ |\n",
    "\n",
    "### 6.4 è®¸å¯è¯å¯¹æ¯”\n",
    "\n",
    "| æ¨¡å‹ | è®¸å¯è¯ | å•†ç”¨ |\n",
    "|------|--------|------|\n",
    "| **Qwenç³»åˆ—** | Apache 2.0 | âœ… |\n",
    "| **LLaMA 2/3** | LLaMA Community | âœ… (æœ‰é™åˆ¶) |\n",
    "| **DeepSeek** | MIT | âœ… |\n",
    "| **Mistral** | Apache 2.0 | âœ… |\n",
    "| **GLM** | è‡ªå®šä¹‰ | âš ï¸ éœ€ç¡®è®¤ |\n",
    "| **GPT-4, Claude** | é—­æº | âŒ API only |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# æ¨¡å‹é€‰æ‹©å†³ç­–æ ‘å¯è§†åŒ–\nfrom matplotlib.patches import FancyBboxPatch, FancyArrowPatch\n\nfig, ax = plt.subplots(figsize=(14, 10))\nax.set_xlim(0, 14)\nax.set_ylim(0, 10)\nax.axis('off')\n\n# å®šä¹‰èŠ‚ç‚¹\ndef add_box(ax, x, y, text, color='lightblue', width=2.5, height=0.8):\n    box = FancyBboxPatch((x-width/2, y-height/2), width, height,\n                         boxstyle=\"round,pad=0.1\", \n                         edgecolor='black', facecolor=color, linewidth=2)\n    ax.add_patch(box)\n    ax.text(x, y, text, ha='center', va='center', fontsize=10, weight='bold')\n\ndef add_arrow(ax, x1, y1, x2, y2, label=''):\n    arrow = FancyArrowPatch((x1, y1), (x2, y2),\n                           arrowstyle='->', mutation_scale=20,\n                           linewidth=2, color='gray')\n    ax.add_patch(arrow)\n    if label:\n        mid_x, mid_y = (x1+x2)/2, (y1+y2)/2\n        ax.text(mid_x, mid_y, label, fontsize=9, ha='center',\n               bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n\n# å†³ç­–æ ‘\nadd_box(ax, 7, 9, 'Choose LLM', '#FFE5B4', width=3)\n\n# ç¬¬ä¸€å±‚åˆ†æ”¯\nadd_box(ax, 3, 7.5, 'Cloud API', '#E6F3FF')\nadd_box(ax, 11, 7.5, 'Local Deploy', '#FFE6E6')\n\nadd_arrow(ax, 6, 8.6, 3.5, 7.9, 'Cost insensitive')\nadd_arrow(ax, 8, 8.6, 10.5, 7.9, 'Data security/Offline')\n\n# äº‘ç«¯APIåˆ†æ”¯\nadd_box(ax, 1.5, 6, 'GPT-4o\\nClaude-3', '#C8E6C9')\nadd_box(ax, 4.5, 6, 'Qwen API\\nDeepSeek', '#C8E6C9')\nadd_arrow(ax, 2.5, 7.1, 1.8, 6.4, 'Performance priority')\nadd_arrow(ax, 3.5, 7.1, 4.2, 6.4, 'Cost priority')\n\n# æœ¬åœ°éƒ¨ç½²åˆ†æ”¯\nadd_box(ax, 8.5, 6, 'Multi-GPU Server', '#FFE6CC')\nadd_box(ax, 11.5, 6, 'Single-GPU/PC', '#FFE6CC')\nadd_arrow(ax, 10.5, 7.1, 9, 6.4, 'Abundant resources')\nadd_arrow(ax, 11.5, 7.1, 11.5, 6.4, 'Limited resources')\n\n# å…·ä½“æ¨¡å‹æ¨è\nadd_box(ax, 7, 4.5, 'Qwen2.5-72B\\nLLaMA-3.1-70B', '#D4EDDA', width=2.8)\nadd_box(ax, 11, 4.5, 'Qwen2.5-7B\\nMistral-7B', '#D4EDDA', width=2.8)\nadd_box(ax, 13, 4.5, 'Qwen2.5-1.5B\\n(Edge devices)', '#D4EDDA', width=2.8)\n\nadd_arrow(ax, 8.5, 5.6, 7.5, 4.9, '70B+ models')\nadd_arrow(ax, 11.2, 5.6, 11, 4.9, '7-14B models')\nadd_arrow(ax, 12, 5.6, 12.8, 4.9, '<3B models')\n\n# ä¸“ä¸šé¢†åŸŸ\nadd_box(ax, 2, 2.5, 'Coding:\\nQwen-Coder\\nDeepSeek-Coder', '#E1BEE7', width=2.5, height=1)\nadd_box(ax, 5.5, 2.5, 'Reasoning:\\nDeepSeek-R1\\nQwQ-32B', '#E1BEE7', width=2.5, height=1)\nadd_box(ax, 9, 2.5, 'Multimodal:\\nQwen2-VL\\nGLM-4V', '#E1BEE7', width=2.5, height=1)\nadd_box(ax, 12.5, 2.5, 'Chinese:\\nQwen2.5\\nGLM-4', '#E1BEE7', width=2.5, height=1)\n\nax.text(7, 0.5, 'Specialized Scenario Recommendations', ha='center', fontsize=12, \n       weight='bold', style='italic', color='#555')\n\nplt.title('LLM Selection Decision Tree', fontsize=16, weight='bold', pad=20)\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. æ€»ç»“ä¸å±•æœ›\n",
    "\n",
    "### 7.1 æ ¸å¿ƒè¦ç‚¹å›é¡¾\n",
    "\n",
    "#### æ–‡æœ¬æ¨¡å‹\n",
    "- **GPTç³»åˆ—**: é—­æºé¢†å¯¼è€…ï¼Œæ€§èƒ½é¡¶å°–\n",
    "- **LLaMAç³»åˆ—**: å¼€æºåŸºåº§ï¼Œç”Ÿæ€ä¸°å¯Œ\n",
    "- **Qwenç³»åˆ—**: ä¸­æ–‡ä¼˜ç§€ï¼ŒæŒç»­è¿­ä»£\n",
    "\n",
    "#### ä¸“ä¸šé¢†åŸŸ\n",
    "- **æ€è€ƒæ¨¡å‹**: DeepSeek-R1, QwQæ¨ç†èƒ½åŠ›å¼º\n",
    "- **ä»£ç æ¨¡å‹**: Qwen-Coder, DeepSeek-Coderç¼–ç¨‹åŠ©æ‰‹\n",
    "- **å¤šæ¨¡æ€**: Qwen-VL, GPT-4oè·¨æ¨¡æ€ç†è§£\n",
    "\n",
    "### 7.2 LLMå‘å±•è¶‹åŠ¿\n",
    "\n",
    "#### 1. æ¨¡å‹è§„æ¨¡\n",
    "```\n",
    "ä¸¤æåˆ†åŒ–:\n",
    "- è¶…å¤§æ¨¡å‹ â†’ ä¸‡äº¿å‚æ•°,MoEæ¶æ„\n",
    "- å°æ¨¡å‹ â†’ ç«¯ä¾§éƒ¨ç½²,æ•ˆç‡ä¼˜åŒ–\n",
    "```\n",
    "\n",
    "#### 2. å¤šæ¨¡æ€èåˆ\n",
    "```\n",
    "æ–‡æœ¬ + å›¾åƒ + éŸ³é¢‘ + è§†é¢‘ â†’ ç»Ÿä¸€æ¨¡å‹\n",
    "```\n",
    "\n",
    "#### 3. é•¿ä¸Šä¸‹æ–‡\n",
    "```\n",
    "2023: 8K-32K\n",
    "2024: 128K-2M\n",
    "2025+: æ— é™ä¸Šä¸‹æ–‡ï¼Ÿ\n",
    "```\n",
    "\n",
    "#### 4. Agentèƒ½åŠ›\n",
    "```\n",
    "LLM â†’ Agent\n",
    "- å·¥å…·è°ƒç”¨\n",
    "- ç¯å¢ƒäº¤äº’\n",
    "- è‡ªä¸»å†³ç­–\n",
    "```\n",
    "\n",
    "#### 5. ä¸ªæ€§åŒ–ä¸å®šåˆ¶\n",
    "```\n",
    "é€šç”¨æ¨¡å‹ â†’ é¢†åŸŸä¸“å®¶\n",
    "- åŒ»ç–—ã€æ³•å¾‹ã€é‡‘èä¸“ç”¨æ¨¡å‹\n",
    "- ä¸ªäººåŒ–çŸ¥è¯†åº“é›†æˆ\n",
    "```\n",
    "\n",
    "#### 6. æ•ˆç‡ä¼˜åŒ–\n",
    "```\n",
    "- é‡åŒ–: INT8, INT4, 1bit\n",
    "- å‰ªæ: ç»“æ„åŒ–/éç»“æ„åŒ–\n",
    "- è’¸é¦: å°æ¨¡å‹å­¦ä¹ å¤§æ¨¡å‹\n",
    "- ç¨€ç–åŒ–: MoE, æ¡ä»¶è®¡ç®—\n",
    "```\n",
    "\n",
    "### 7.3 å…³é”®æŒ‘æˆ˜\n",
    "\n",
    "âŒ **å¹»è§‰é—®é¢˜**: æ¨¡å‹ä»ä¼šç”Ÿæˆä¸å‡†ç¡®ä¿¡æ¯  \n",
    "âŒ **æ¨ç†æˆæœ¬**: å¤§æ¨¡å‹æ¨ç†expensive  \n",
    "âŒ **æ•°æ®éšç§**: è®­ç»ƒæ•°æ®æ³„éœ²é£é™©  \n",
    "âŒ **å¯¹é½é—®é¢˜**: ä»·å€¼è§‚å¯¹é½ä»åœ¨æ¢ç´¢  \n",
    "âŒ **å¯è§£é‡Šæ€§**: é»‘ç›’å†³ç­–éš¾ä»¥è§£é‡Š  \n",
    "\n",
    "### 7.4 æœªæ¥å±•æœ›\n",
    "\n",
    "#### AGIä¹‹è·¯\n",
    "```\n",
    "å½“å‰LLM â†’ å¤šæ¨¡æ€Agent â†’ AGIï¼Ÿ\n",
    "\n",
    "å…³é”®èƒ½åŠ›:\n",
    "- æŒç»­å­¦ä¹ \n",
    "- å¸¸è¯†æ¨ç†\n",
    "- å› æœç†è§£\n",
    "- è‡ªæˆ‘åæ€\n",
    "```\n",
    "\n",
    "#### åº”ç”¨åœºæ™¯æ‰©å±•\n",
    "- ğŸ¥ **åŒ»ç–—**: AIè¯Šæ–­åŠ©æ‰‹ã€è¯ç‰©ç ”å‘\n",
    "- âš–ï¸ **æ³•å¾‹**: åˆåŒå®¡æŸ¥ã€åˆ¤ä¾‹æ£€ç´¢\n",
    "- ğŸ“ **æ•™è‚²**: ä¸ªæ€§åŒ–è¾…å¯¼ã€çŸ¥è¯†å›¾è°±\n",
    "- ğŸ­ **å·¥ä¸š**: æ™ºèƒ½åˆ¶é€ ã€ä¾›åº”é“¾ä¼˜åŒ–\n",
    "- ğŸ”¬ **ç§‘ç ”**: æ–‡çŒ®ç»¼è¿°ã€å®éªŒè®¾è®¡\n",
    "\n",
    "### 7.5 å­¦ä¹ å»ºè®®\n",
    "\n",
    "1. **ç†è®ºåŸºç¡€**: æ·±å…¥ç†è§£Transformeræ¶æ„\n",
    "2. **åŠ¨æ‰‹å®è·µ**: \n",
    "   - ä½¿ç”¨å¼€æºæ¨¡å‹ï¼ˆQwen, LLaMAï¼‰\n",
    "   - å­¦ä¹ éƒ¨ç½²å·¥å…·ï¼ˆvLLM, llama.cppï¼‰\n",
    "   - å°è¯•å¾®è°ƒï¼ˆLoRA, QLoRAï¼‰\n",
    "3. **å…³æ³¨å‰æ²¿**: è·Ÿè¸ªæœ€æ–°è®ºæ–‡å’Œæ¨¡å‹å‘å¸ƒ\n",
    "4. **åº”ç”¨é©±åŠ¨**: ç»“åˆå®é™…åœºæ™¯è§£å†³é—®é¢˜\n",
    "\n",
    "### 7.6 å»¶ä¼¸èµ„æº\n",
    "\n",
    "ğŸ“š **æ¨¡å‹ä»“åº“**:\n",
    "- Hugging Face Model Hub\n",
    "- ModelScope\n",
    "- GitHub (å„æ¨¡å‹å®˜æ–¹repo)\n",
    "\n",
    "ğŸ“– **å­¦ä¹ èµ„æ–™**:\n",
    "- [LLM Course](https://github.com/mlabonne/llm-course)\n",
    "- [Awesome-LLM](https://github.com/Hannibal046/Awesome-LLM)\n",
    "- å„æ¨¡å‹çš„æŠ€æœ¯æŠ¥å‘Šå’Œè®ºæ–‡\n",
    "\n",
    "ğŸ› ï¸ **å·¥å…·é“¾**:\n",
    "- vLLM: é«˜æ•ˆæ¨ç†å¼•æ“\n",
    "- llama.cpp: è½»é‡çº§éƒ¨ç½²\n",
    "- LangChain: åº”ç”¨å¼€å‘æ¡†æ¶\n",
    "- Ollama: æœ¬åœ°æ¨¡å‹ç®¡ç†\n",
    "\n",
    "---\n",
    "\n",
    "## è¯¾åæ€è€ƒ\n",
    "\n",
    "1. ä¸ºä»€ä¹ˆè¿‘å¹´æ¥Decoder-onlyæ¶æ„æˆä¸ºä¸»æµï¼Œè€ŒEncoder-Decoderé€æ¸å‡å°‘ï¼Ÿ\n",
    "\n",
    "2. å¼€æºæ¨¡å‹ï¼ˆå¦‚Qwen, LLaMAï¼‰ä¸é—­æºæ¨¡å‹ï¼ˆå¦‚GPT-4ï¼‰çš„æ€§èƒ½å·®è·åœ¨ç¼©å°ï¼Œè¿™å¯¹AIè¡Œä¸šæœ‰ä»€ä¹ˆå½±å“ï¼Ÿ\n",
    "\n",
    "3. æ€è€ƒæ¨¡å‹ï¼ˆå¦‚DeepSeek-R1ï¼‰å±•ç°äº†å¼ºå¤§çš„æ¨ç†èƒ½åŠ›ï¼Œä½†æ¨ç†é€Ÿåº¦è¾ƒæ…¢ã€‚å¦‚ä½•æƒè¡¡æ€§èƒ½ä¸æ•ˆç‡ï¼Ÿ\n",
    "\n",
    "4. å¤šæ¨¡æ€æ¨¡å‹èƒ½å¦çœŸæ­£å®ç°\"çœ‹æ‡‚\"å›¾åƒå’Œè§†é¢‘ï¼Ÿå®ƒä»¬çš„ç†è§£ä¸äººç±»æœ‰ä½•ä¸åŒï¼Ÿ\n",
    "\n",
    "5. å¦‚æœè¦ä¸ºä½ çš„å…¬å¸/é¡¹ç›®é€‰æ‹©ä¸€ä¸ªLLMï¼Œä½ ä¼šå¦‚ä½•å†³ç­–ï¼Ÿè€ƒè™‘å“ªäº›å› ç´ ï¼Ÿ\n",
    "\n",
    "---\n",
    "\n",
    "**è¯¾ç¨‹æ€»ç»“**  \n",
    "æ­å–œå®ŒæˆML/DLå·¥ä½œåŠçš„å…¨éƒ¨4èŠ‚è¯¾ï¼ä½ å·²ç»ä»æœºå™¨å­¦ä¹ åŸºç¡€å‡ºå‘ï¼Œç»å†äº†ç¥ç»ç½‘ç»œã€Transformeræ¶æ„ï¼Œæœ€ç»ˆäº†è§£äº†å½“å‰æœ€å‰æ²¿çš„å¤§è¯­è¨€æ¨¡å‹ã€‚\n",
    "\n",
    "**ä¸‹ä¸€æ­¥**:  \n",
    "åœ¨æœªæ¥çš„è¿›é˜¶è¯¾ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†å­¦ä¹ :\n",
    "- ğŸ‹ï¸ LLMè®­ç»ƒ: é¢„è®­ç»ƒã€å¾®è°ƒã€RLHF\n",
    "- ğŸš€ LLMæ¨ç†: éƒ¨ç½²ä¼˜åŒ–ã€åŠ é€ŸæŠ€æœ¯\n",
    "- ğŸ¤– LLMåº”ç”¨: Agentå¼€å‘ã€RAGç³»ç»Ÿ\n",
    "\n",
    "ç»§ç»­å­¦ä¹ ï¼Œæ¢ç´¢AIçš„æ— é™å¯èƒ½ï¼ ğŸ‰"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}